{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Artificial Neural Networks and Deep Learning**\n\n## Training LSTM and Bidirectional LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FdqcMXk96rS"
   },
   "source": [
    "## \ud83c\udf10 **Google Drive Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxUZy3U-fjcm"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\")\n",
    "current_dir = \"/gdrive/My\\\\ Drive/[2025-2026]\\\\ AN2DL/Lecture\\\\ 4\"\n",
    "%cd $current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfehjCy896Fd"
   },
   "source": [
    "## \u2699\ufe0f **Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x47Uv8R9Akcl"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "logs_dir = \"tensorboard\"\n",
    "!pkill -f tensorboard\n",
    "%load_ext tensorboard\n",
    "!mkdir -p models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import copy\n",
    "import shutil\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRK9IPIc-ZEz"
   },
   "source": [
    "## \u23f3 **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yW6Vy5xCBwO"
   },
   "outputs": [],
   "source": [
    "# Set environment variables for Activity Recognition dataset\n",
    "os.environ[\"DATASET_NAME\"] = \"activities_recognition.txt\"\n",
    "os.environ[\"DATASET_URL\"] = \"1QqyAJndGqPa-pWgyI63SuBAT__GnmL1b\"\n",
    "\n",
    "# Check if Activity Recognition dataset exists and download if not\n",
    "if not os.path.exists(os.environ[\"DATASET_NAME\"]):\n",
    "    print(\"Downloading Activity Recognition dataset...\")\n",
    "    !gdown -q ${DATASET_URL} -O ${DATASET_NAME}\n",
    "    print(\"Activity Recognition dataset downloaded!\")\n",
    "else:\n",
    "    print(\"Activity Recognition dataset already downloaded. Using cached data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTsqFuL6SpAm"
   },
   "source": [
    "## \ud83d\udd04 **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6R_KBCls6z0"
   },
   "outputs": [],
   "source": [
    "# Identify unique activity executions per user by creating a composite ID\n",
    "df['id'] = df['user_id'].astype('str') + '_' + df['activity'].astype('str')\n",
    "\n",
    "# Print the number of unique activity executions\n",
    "print(f'The dataset is composed of {df[\"id\"].nunique()} different activity executions')\n",
    "\n",
    "# Count the unique IDs for distinct activity executions\n",
    "n_users = len(df['id'].unique())\n",
    "\n",
    "# Create a custom colour map for better distinction of unique IDs\n",
    "colors = plt.cm.turbo(np.linspace(0, 1, n_users))\n",
    "\n",
    "# Visualise the count of timestamps per unique ID\n",
    "plt.figure(figsize=(17, 5))\n",
    "sns.countplot(\n",
    "    x='id',\n",
    "    data=df,\n",
    "    order=df['id'].value_counts().index,\n",
    "    palette=colors\n",
    ")\n",
    "\n",
    "# Set the title of the plot and disable x-axis labels for clarity\n",
    "plt.title('Per Id Timestamps')\n",
    "plt.xticks([], [])  # Remove x-axis ticks and labels\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYLncaLxyCJO"
   },
   "outputs": [],
   "source": [
    "# Display the first five rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8HtgcBGAzaD"
   },
   "outputs": [],
   "source": [
    "# Get unique user IDs and shuffle them\n",
    "unique_users = df['user_id'].unique()\n",
    "random.seed(SEED) # Ensure reproducibility of shuffling\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "# Define the number of users for validation and test sets\n",
    "N_VAL_USERS = 5 # You can change this number\n",
    "N_TEST_USERS = 5 # You can change this number\n",
    "\n",
    "# Calculate the number of users for the training set\n",
    "n_train_users = len(unique_users) - N_VAL_USERS - N_TEST_USERS\n",
    "\n",
    "# Split the shuffled user IDs into training, validation, and test sets\n",
    "train_users = unique_users[:n_train_users]\n",
    "val_users = unique_users[n_train_users:n_train_users + N_VAL_USERS]\n",
    "test_users = unique_users[n_train_users + N_VAL_USERS:]\n",
    "\n",
    "# Split the dataset into training, validation, and test sets based on user IDs\n",
    "df_train = df[df['user_id'].isin(train_users)]\n",
    "df_val = df[df['user_id'].isin(val_users)]\n",
    "df_test = df[df['user_id'].isin(test_users)]\n",
    "\n",
    "# Print the shapes of the training, validation, and test sets\n",
    "print(f'Training set shape: {df_train.shape}')\n",
    "print(f'Validation set shape: {df_val.shape}')\n",
    "print(f'Test set shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_f41l7pX_JmC"
   },
   "outputs": [],
   "source": [
    "# Initialise a dictionary to count occurrences of each activity in the training set\n",
    "training_labels = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 0,\n",
    "    'Upstairs': 0,\n",
    "    'Downstairs': 0,\n",
    "    'Sitting': 0,\n",
    "    'Standing': 0\n",
    "}\n",
    "\n",
    "# Count occurrences of each activity for unique IDs in the training set\n",
    "for id in df_train['id'].unique():\n",
    "    label = df_train[df_train['id'] == id]['activity'].values[0]\n",
    "    training_labels[label] += 1\n",
    "\n",
    "# Print the distribution of training labels\n",
    "print('Training labels:', training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed577kr5F8HQ"
   },
   "outputs": [],
   "source": [
    "# Initialise a dictionary to count occurrences of each activity in the validation set\n",
    "val_labels = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 0,\n",
    "    'Upstairs': 0,\n",
    "    'Downstairs': 0,\n",
    "    'Sitting': 0,\n",
    "    'Standing': 0\n",
    "}\n",
    "\n",
    "# Count occurrences of each activity for unique IDs in the validation set\n",
    "for id in df_val['id'].unique():\n",
    "    label = df_val[df_val['id'] == id]['activity'].values[0]\n",
    "    val_labels[label] += 1\n",
    "\n",
    "# Print the distribution of validation labels\n",
    "print('Validation labels:', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2_SOzetAN_V"
   },
   "outputs": [],
   "source": [
    "# Initialise a dictionary to count occurrences of each activity in the test set\n",
    "test_labels = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 0,\n",
    "    'Upstairs': 0,\n",
    "    'Downstairs': 0,\n",
    "    'Sitting': 0,\n",
    "    'Standing': 0\n",
    "}\n",
    "\n",
    "# Count occurrences of each activity for unique IDs in the test set\n",
    "for id in df_test['id'].unique():\n",
    "    label = df_test[df_test['id'] == id]['activity'].values[0]\n",
    "    test_labels[label] += 1\n",
    "\n",
    "# Print the distribution of test labels\n",
    "print('Test labels:', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ec5AFCLqFvd0"
   },
   "outputs": [],
   "source": [
    "# Define a mapping of activity names to integer labels\n",
    "label_mapping = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 1,\n",
    "    'Upstairs': 2,\n",
    "    'Downstairs': 3,\n",
    "    'Sitting': 4,\n",
    "    'Standing': 5\n",
    "}\n",
    "\n",
    "# Map activity names to integers in the training set\n",
    "df_train['activity'] = df_train['activity'].map(label_mapping)\n",
    "\n",
    "# Map activity names to integers in the validation set\n",
    "df_val['activity'] = df_val['activity'].map(label_mapping)\n",
    "\n",
    "# Map activity names to integers in the test set\n",
    "df_test['activity'] = df_test['activity'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8YZJJSvAmvJ"
   },
   "outputs": [],
   "source": [
    "# Define the columns to be normalised\n",
    "scale_columns = ['x_axis', 'y_axis', 'z_axis']\n",
    "\n",
    "# Calculate the minimum and maximum values from the training data only\n",
    "mins = df_train[scale_columns].min()\n",
    "maxs = df_train[scale_columns].max()\n",
    "\n",
    "# Apply normalisation to the specified columns in all datasets\n",
    "for column in scale_columns:\n",
    "    # Normalise the training set\n",
    "    df_train[column] = (df_train[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "    # Normalise the validation set\n",
    "    df_val[column] = (df_val[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "    # Normalise the test set\n",
    "    df_test[column] = (df_test[column] - mins[column]) / (maxs[column] - mins[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sh4k_B_9CbmF"
   },
   "outputs": [],
   "source": [
    "# Display the first five rows of the training DataFrame\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQYPViwbwgTk"
   },
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "WINDOW_SIZE = 200\n",
    "\n",
    "# Define the stride for overlapping windows\n",
    "STRIDE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xy2VJmHIu6iJ"
   },
   "outputs": [],
   "source": [
    "# Define a function to build sequences from the dataset\n",
    "def build_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to ensure the window is divisible by the stride\n",
    "    assert window % stride == 0\n",
    "\n",
    "    # Initialise lists to store sequences and their corresponding labels\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over unique IDs in the DataFrame\n",
    "    for id in df['id'].unique():\n",
    "        # Extract sensor data for the current ID\n",
    "        temp = df[df['id'] == id][['x_axis', 'y_axis', 'z_axis']].values\n",
    "\n",
    "        # Retrieve the activity label for the current ID\n",
    "        label = df[df['id'] == id]['activity'].values[0]\n",
    "\n",
    "        # Calculate padding length to ensure full windows\n",
    "        padding_len = window - len(temp) % window\n",
    "\n",
    "        # Create zero padding and concatenate with the data\n",
    "        padding = np.zeros((padding_len, 3), dtype='float32')\n",
    "        temp = np.concatenate((temp, padding))\n",
    "\n",
    "        # Build feature windows and associate them with labels\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp):\n",
    "            dataset.append(temp[idx:idx + window])\n",
    "            labels.append(label)\n",
    "            idx += stride\n",
    "\n",
    "    # Convert lists to numpy arrays for further processing\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vs7s2fru6fB"
   },
   "outputs": [],
   "source": [
    "# Generate sequences and labels for the training set\n",
    "X_train, y_train = build_sequences(df_train, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "# Generate sequences and labels for the validation set\n",
    "X_val, y_val = build_sequences(df_val, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "# Generate sequences and labels for the test set\n",
    "X_test, y_test = build_sequences(df_test, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "# Print the shapes of the generated datasets and their labels\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkUqhy__KMnr"
   },
   "outputs": [],
   "source": [
    "# Define the input shape based on the training data\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define the number of classes based on the categorical labels\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4g715TtSytf"
   },
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjhjKSW3WysO"
   },
   "outputs": [],
   "source": [
    "# Define the batch size, which is the number of samples in each batch\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIkKaZJkW0z_"
   },
   "outputs": [],
   "source": [
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZR5CG9qW2AI"
   },
   "outputs": [],
   "source": [
    "# Create data loaders with different settings for each phase\n",
    "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPpKL3_NW2dq"
   },
   "outputs": [],
   "source": [
    "# Get one batch from the training data loader\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Features batch shape:\", xb.shape)\n",
    "    print(\"Labels batch shape:\", yb.shape)\n",
    "    break # Stop after getting one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfejlDqBYOOM"
   },
   "source": [
    "## \ud83d\udee0\ufe0f **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VraH-QTDxHWD"
   },
   "outputs": [],
   "source": [
    "def recurrent_summary(model, input_size):\n",
    "    \"\"\"\n",
    "    Custom summary function that emulates torchinfo's output while correctly\n",
    "    counting parameters for RNN/GRU/LSTM layers.\n",
    "\n",
    "    This function is designed for models whose direct children are\n",
    "    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to analyze.\n",
    "        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store output shapes captured by forward hooks\n",
    "    output_shapes = {}\n",
    "    # List to track hook handles for later removal\n",
    "    hooks = []\n",
    "\n",
    "    def get_hook(name):\n",
    "        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            # Handle RNN layer outputs (returns a tuple)\n",
    "            if isinstance(output, tuple):\n",
    "                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n",
    "                shape1 = list(output[0].shape)\n",
    "                shape1[0] = -1  # Replace batch dimension with -1\n",
    "\n",
    "                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n",
    "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
    "                    shape2 = list(output[1][0].shape)  # Extract h_n only\n",
    "                else:  # RNN/GRU case: h_n only\n",
    "                    shape2 = list(output[1].shape)\n",
    "\n",
    "                # Replace batch dimension (middle position) with -1\n",
    "                shape2[1] = -1\n",
    "\n",
    "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
    "\n",
    "            # Handle standard layer outputs (e.g., Linear)\n",
    "            else:\n",
    "                shape = list(output.shape)\n",
    "                shape[0] = -1  # Replace batch dimension with -1\n",
    "                output_shapes[name] = f\"{shape}\"\n",
    "        return hook\n",
    "\n",
    "    # 1. Determine the device where model parameters reside\n",
    "    try:\n",
    "        device = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        device = torch.device(\"cpu\")  # Fallback for models without parameters\n",
    "\n",
    "    # 2. Create a dummy input tensor with batch_size=1\n",
    "    dummy_input = torch.randn(1, *input_size).to(device)\n",
    "\n",
    "    # 3. Register forward hooks on target layers\n",
    "    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
    "            # Register the hook and store its handle for cleanup\n",
    "            hook_handle = module.register_forward_hook(get_hook(name))\n",
    "            hooks.append(hook_handle)\n",
    "\n",
    "    # 4. Execute a dummy forward pass in evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            model(dummy_input)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during dummy forward pass: {e}\")\n",
    "            # Clean up hooks even if an error occurs\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "            return\n",
    "\n",
    "    # 5. Remove all registered hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    # --- 6. Print the summary table ---\n",
    "\n",
    "    print(\"-\" * 79)\n",
    "    # Column headers\n",
    "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
    "    print(\"=\" * 79)\n",
    "\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "\n",
    "    # Iterate through modules again to collect and display parameter information\n",
    "    for name, module in model.named_children():\n",
    "        if name in output_shapes:\n",
    "            # Count total and trainable parameters for this module\n",
    "            module_params = sum(p.numel() for p in module.parameters())\n",
    "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "            total_params += module_params\n",
    "            total_trainable_params += trainable_params\n",
    "\n",
    "            # Format strings for display\n",
    "            layer_name = f\"{name} ({type(module).__name__})\"\n",
    "            output_shape_str = str(output_shapes[name])\n",
    "            params_str = f\"{trainable_params:,}\"\n",
    "\n",
    "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
    "\n",
    "    print(\"=\" * 79)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
    "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogXWKej_fl6p"
   },
   "outputs": [],
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic RNN classifier (RNN, LSTM, GRU).\n",
    "    Uses the last hidden state for classification.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_classes,\n",
    "            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n",
    "            bidirectional=False,\n",
    "            dropout_rate=0.2\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Map string name to PyTorch RNN class\n",
    "        rnn_map = {\n",
    "            'RNN': nn.RNN,\n",
    "            'LSTM': nn.LSTM,\n",
    "            'GRU': nn.GRU\n",
    "        }\n",
    "\n",
    "        if rnn_type not in rnn_map:\n",
    "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
    "\n",
    "        rnn_module = rnn_map[rnn_type]\n",
    "\n",
    "        # Dropout is only applied between layers (if num_layers > 1)\n",
    "        dropout_val = dropout_rate if num_layers > 1 else 0\n",
    "\n",
    "        # Create the recurrent layer\n",
    "        self.rnn = rnn_module(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_val\n",
    "        )\n",
    "\n",
    "        # Calculate input size for the final classifier\n",
    "        if self.bidirectional:\n",
    "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
    "        else:\n",
    "            classifier_input_size = hidden_size\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(classifier_input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_length, input_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "\n",
    "        # LSTM returns (h_n, c_n), we only need h_n\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            hidden = hidden[0]\n",
    "\n",
    "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "\n",
    "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
    "            # Final shape: (batch_size, hidden_size * 2)\n",
    "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            # Take the last layer's hidden state\n",
    "            # Final shape: (batch_size, hidden_size)\n",
    "            hidden_to_classify = hidden[-1]\n",
    "\n",
    "        # Get logits\n",
    "        logits = self.classifier(hidden_to_classify)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Create model and display architecture with parameter count\n",
    "rnn_model = RecurrentClassifier(\n",
    "    input_size=input_shape[-1], # Pass the number of features\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=0.,\n",
    "    rnn_type='RNN'\n",
    "    ).to(device)\n",
    "recurrent_summary(rnn_model, input_size=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BywFq9R9ma8K"
   },
   "source": [
    "## \ud83e\uddee **Network and Training Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxtAqB60mcAd"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 500\n",
    "PATIENCE = 50\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_LAYERS = 2        # Hidden layers\n",
    "HIDDEN_SIZE = 128        # Neurons per layer\n",
    "\n",
    "# Regularisation\n",
    "DROPOUT_RATE = 0.2         # Dropout probability\n",
    "L1_LAMBDA = 0            # L1 penalty\n",
    "L2_LAMBDA = 0            # L2 penalty\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llBX--t7NAE3"
   },
   "source": [
    "### **Long Short-Term Memory (LSTM)**\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1AHDpl1vMWow9xUhP4C7nZLJjk_kNos_I\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "astW9HWsOik3"
   },
   "outputs": [],
   "source": [
    "# Create model and display architecture with parameter count\n",
    "rnn_model = RecurrentClassifier(\n",
    "    input_size=input_shape[-1], # Pass the number of features\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=HIDDEN_LAYERS,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    bidirectional=False,\n",
    "    rnn_type='LSTM'\n",
    "    ).to(device)\n",
    "recurrent_summary(rnn_model, input_size=input_shape)\n",
    "\n",
    "# Set up TensorBoard logging and save model architecture\n",
    "experiment_name = \"lstm\"\n",
    "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
    "x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
    "writer.add_graph(rnn_model, x)\n",
    "\n",
    "# Define optimizer with L2 regularization\n",
    "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "\n",
    "# Enable mixed precision training for GPU acceleration\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEuRDgEEOiiQ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model and track training history\n",
    "rnn_model, training_history = fit(\n",
    "    model=rnn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    verbose=1,\n",
    "    experiment_name=\"lstm\",\n",
    "    patience=PATIENCE\n",
    "    )\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if training_history['val_f1'][-1] > best_performance:\n",
    "    best_model = rnn_model\n",
    "    best_performance = training_history['val_f1'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Mt_ZjMnjOifb"
   },
   "outputs": [],
   "source": [
    "# @title Plot Hitory\n",
    "# Create a figure with two side-by-side subplots (two columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "\n",
    "# Plot of training and validation loss on the first axis\n",
    "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot of training and validation accuracy on the second axis\n",
    "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
    "ax2.set_title('F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zxaww_Kne7m6"
   },
   "outputs": [],
   "source": [
    "# @title Plot Confusion Matrix\n",
    "# Collect predictions and ground truth labels\n",
    "val_preds, val_targets = [], []\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "\n",
    "        # Forward pass: get model predictions\n",
    "        logits = rnn_model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        # Store batch results\n",
    "        val_preds.append(preds)\n",
    "        val_targets.append(yb.numpy())\n",
    "\n",
    "# Combine all batches into single arrays\n",
    "val_preds = np.concatenate(val_preds)\n",
    "val_targets = np.concatenate(val_targets)\n",
    "\n",
    "# Calculate overall validation metrics\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
    "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
    "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
    "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
    "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
    "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for detailed error analysis\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "\n",
    "# Create numeric labels for heatmap annotation\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Visualise confusion matrix\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='',\n",
    "            cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix \u2014 Validation Set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bPCQoeXPjQY"
   },
   "source": [
    "### **Bidirectional Long Short-Term Memory (BiLSTM)**\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1-W_s-cH_9wv-rmfKaa5giXzIXpdRFUpf\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwQ_6RuoOick"
   },
   "outputs": [],
   "source": [
    "# Create model and display architecture with parameter count\n",
    "rnn_model = RecurrentClassifier(\n",
    "    input_size=input_shape[-1], # Pass the number of features\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=HIDDEN_LAYERS,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    bidirectional=True,\n",
    "    rnn_type='LSTM'\n",
    "    ).to(device)\n",
    "recurrent_summary(rnn_model, input_size=input_shape)\n",
    "\n",
    "# Set up TensorBoard logging and save model architecture\n",
    "experiment_name = \"bi_lstm\"\n",
    "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
    "x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
    "writer.add_graph(rnn_model, x)\n",
    "\n",
    "# Define optimizer with L2 regularization\n",
    "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "\n",
    "# Enable mixed precision training for GPU acceleration\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yNxK3ctOiZ4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model and track training history\n",
    "rnn_model, training_history = fit(\n",
    "    model=rnn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    verbose=1,\n",
    "    experiment_name=\"bi_lstm\",\n",
    "    patience=PATIENCE\n",
    "    )\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if training_history['val_f1'][-1] > best_performance:\n",
    "    best_model = rnn_model\n",
    "    best_performance = training_history['val_f1'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxWzzUO0fCY6",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Plot Hitory\n",
    "# Create a figure with two side-by-side subplots (two columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "\n",
    "# Plot of training and validation loss on the first axis\n",
    "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot of training and validation accuracy on the second axis\n",
    "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
    "ax2.set_title('F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM09gbAJfCWK",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Plot Confusion Matrix\n",
    "# Collect predictions and ground truth labels\n",
    "val_preds, val_targets = [], []\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "\n",
    "        # Forward pass: get model predictions\n",
    "        logits = rnn_model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        # Store batch results\n",
    "        val_preds.append(preds)\n",
    "        val_targets.append(yb.numpy())\n",
    "\n",
    "# Combine all batches into single arrays\n",
    "val_preds = np.concatenate(val_preds)\n",
    "val_targets = np.concatenate(val_targets)\n",
    "\n",
    "# Calculate overall validation metrics\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
    "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
    "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
    "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
    "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
    "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for detailed error analysis\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "\n",
    "# Create numeric labels for heatmap annotation\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Visualise confusion matrix\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='',\n",
    "            cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix \u2014 Validation Set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "collapsed_sections": [
    "3bPCQoeXPjQY"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}